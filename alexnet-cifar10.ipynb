{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0ce7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\envs\\saba\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\ASUS\\anaconda3\\envs\\saba\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "\n",
    "# torch.cuda=torch.cuda.empty_cache()\n",
    "# import gc\n",
    "# del variables\n",
    "# gc.collect()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ecd87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_features = self.features(x)\n",
    "        flatten = conv_features.view(conv_features.size(0), -1)\n",
    "        fc = self.fc_layers(flatten)\n",
    "        return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50445c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.921\n",
      "Time: 109.79388880729675\n",
      "[1,  4000] loss: 1.576\n",
      "Time: 213.33439755439758\n",
      "[1,  6000] loss: 1.419\n",
      "Time: 319.1564643383026\n",
      "[1,  8000] loss: 1.302\n",
      "Time: 424.67108845710754\n",
      "[1, 10000] loss: 1.209\n",
      "Time: 531.2950711250305\n",
      "[1, 12000] loss: 1.114\n",
      "Time: 638.0463304519653\n",
      "[2,  2000] loss: 1.007\n",
      "Time: 114.68207263946533\n",
      "[2,  4000] loss: 0.969\n",
      "Time: 219.15903544425964\n",
      "[2,  6000] loss: 0.948\n",
      "Time: 323.0640630722046\n",
      "[2,  8000] loss: 0.931\n",
      "Time: 426.4295208454132\n",
      "[2, 10000] loss: 0.877\n",
      "Time: 530.8686780929565\n",
      "[2, 12000] loss: 0.857\n",
      "Time: 635.7542481422424\n",
      "[3,  2000] loss: 0.747\n",
      "Time: 112.25724291801453\n",
      "[3,  4000] loss: 0.747\n",
      "Time: 218.93959259986877\n",
      "[3,  6000] loss: 0.710\n",
      "Time: 325.68727254867554\n",
      "[3,  8000] loss: 0.716\n",
      "Time: 432.0996022224426\n",
      "[3, 10000] loss: 0.715\n",
      "Time: 539.1009304523468\n",
      "[3, 12000] loss: 0.703\n",
      "Time: 644.1996545791626\n",
      "[4,  2000] loss: 0.584\n",
      "Time: 112.11592888832092\n",
      "[4,  4000] loss: 0.576\n",
      "Time: 219.06439685821533\n",
      "[4,  6000] loss: 0.579\n",
      "Time: 324.4422824382782\n",
      "[4,  8000] loss: 0.596\n",
      "Time: 429.97071647644043\n",
      "[4, 10000] loss: 0.591\n",
      "Time: 534.8621788024902\n",
      "[4, 12000] loss: 0.569\n",
      "Time: 641.1529057025909\n",
      "[5,  2000] loss: 0.460\n",
      "Time: 112.95669150352478\n",
      "[5,  4000] loss: 0.472\n",
      "Time: 219.86615133285522\n",
      "[5,  6000] loss: 0.473\n",
      "Time: 326.0081331729889\n",
      "[5,  8000] loss: 0.483\n",
      "Time: 433.4682285785675\n",
      "[5, 10000] loss: 0.477\n",
      "Time: 540.0016069412231\n",
      "[5, 12000] loss: 0.470\n",
      "Time: 646.9341928958893\n",
      "[6,  2000] loss: 0.354\n",
      "Time: 112.95950984954834\n",
      "[6,  4000] loss: 0.371\n",
      "Time: 219.5102198123932\n",
      "[6,  6000] loss: 0.374\n",
      "Time: 327.13213562965393\n",
      "[6,  8000] loss: 0.401\n",
      "Time: 432.8802742958069\n",
      "[6, 10000] loss: 0.397\n",
      "Time: 537.7630391120911\n",
      "[6, 12000] loss: 0.411\n",
      "Time: 642.6214346885681\n",
      "[7,  2000] loss: 0.290\n",
      "Time: 111.8294792175293\n",
      "[7,  4000] loss: 0.324\n",
      "Time: 216.66942691802979\n",
      "[7,  6000] loss: 0.307\n",
      "Time: 321.8832929134369\n",
      "[7,  8000] loss: 0.320\n",
      "Time: 428.72389125823975\n",
      "[7, 10000] loss: 0.327\n",
      "Time: 535.3809032440186\n",
      "[7, 12000] loss: 0.337\n",
      "Time: 640.8301379680634\n",
      "Finished Training of AlexNet\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # AlexNet.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(AlexNet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = AlexNet() \n",
    "model = model.to(device=device) \n",
    "\n",
    "## Loss and optimizer\n",
    "learning_rate = 1e-4 \n",
    "load_model = True\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= learning_rate) \n",
    "\n",
    "\n",
    "import time\n",
    "for epoch in range(7):  \n",
    "\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         scores = model(data)\n",
    "#         loss = criterion(scores,targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         loss_ep += loss.item()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Time\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            print('Time:',time_taken)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training of AlexNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46760780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 79.31 %\n"
     ]
    }
   ],
   "source": [
    "#Testing Accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "845504fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 79 %\n",
      "Accuracy of   car : 91 %\n",
      "Accuracy of  bird : 68 %\n",
      "Accuracy of   cat : 63 %\n",
      "Accuracy of  deer : 75 %\n",
      "Accuracy of   dog : 71 %\n",
      "Accuracy of  frog : 83 %\n",
      "Accuracy of horse : 82 %\n",
      "Accuracy of  ship : 92 %\n",
      "Accuracy of truck : 86 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b993b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy =  79.34\n"
     ]
    }
   ],
   "source": [
    "#Verifying average accuracy of the network\n",
    "avg = 0\n",
    "for i in range(10):\n",
    "  temp = (100 * class_correct[i] / class_total[i])\n",
    "  avg = avg + temp\n",
    "avg = avg/10\n",
    "print('Average accuracy = ', avg)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8de77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
